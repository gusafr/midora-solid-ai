{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"solid.ai \u2014 Organizational Nervous System for AI-Native Companies","text":"<p>solid.ai is the open framework for designing intelligent, ethical, and adaptive organizations where humans and AI co-create value. The repository captures the reference model, governance patterns, and playbooks required to connect purpose, data, intelligence, automation, and organizational design into one cohesive operating system.</p>"},{"location":"#why-solidai","title":"Why solid.ai","text":"<ul> <li>Align strategic intent with automated execution through a purpose-first architecture.</li> <li>Treat AI agents as accountable teammates inside transparent, observable systems.</li> <li>Grow organizations as living ecosystems that continuously learn and improve.</li> </ul>"},{"location":"#core-layers","title":"Core Layers","text":"Layer Focus Outcomes Purpose Layer Strategic intent, ethics, human oversight Coherent direction and alignment Data Spine Shared data contracts, interoperability, observability Trusted information flow Cognitive Layer AI agents, orchestration (e.g., MAGI), learning loops Responsible intelligence Automation Mesh Event-driven execution, SIPOC automation patterns Reliable, adaptive operations Organizational Layer Squads, pools, adaptive topology Symbiotic human\u2013AI collaboration Governance &amp; Ethics Layer Accountability, transparency, auditability Trustworthy scale"},{"location":"#repository-structure","title":"Repository Structure","text":"Path Description <code>README.md</code> Entry point and orientation for contributors and adopters <code>LICENSE</code> MIT License granting open-source usage <code>CODE_OF_CONDUCT.md</code> Community expectations and escalation paths <code>CONTRIBUTING.md</code> Workflow for RFCs, ADRs, and documentation updates <code>MANIFESTO/solid-ai-manifesto-v1.md</code> Foundational manifesto outlining philosophy and roadmap <code>DOCS/</code> Modular documentation covering principles, architecture, governance, and glossary <code>DIAGRAMS/</code> Mermaid source files for architecture and organizational flows <code>RFC/</code> Request for Comments governing strategic evolutions <code>ADR/</code> Architecture Decision Records tracking technical choices <code>PLAYBOOKS/</code> Operational guides for squads, pools, operations, and AI integration <code>mkdocs.yml</code> MkDocs Material configuration for publishing the site"},{"location":"#quick-start","title":"Quick Start","text":"<ol> <li>Clone the repository:     <pre><code>git clone https://github.com/gusafr/solid.ai.git\ncd solid.ai\n</code></pre></li> <li>(Optional) Prepare the documentation site locally:     <pre><code>python -m venv .venv\n.venv\\Scripts\\Activate.ps1\npip install mkdocs-material mkdocs-mermaid2-plugin\nmkdocs serve\n</code></pre></li> <li>Open <code>http://127.0.0.1:8000</code> in your browser to explore the docs.</li> </ol>"},{"location":"#contributing","title":"Contributing","text":"<p>We follow an RFC-first change management process. Please review <code>CONTRIBUTING.md</code> before proposing updates. Every change that touches the core architecture or governance must include an RFC or ADR reference.</p>"},{"location":"#license","title":"License","text":"<p>Distributed under the MIT License. See <code>LICENSE</code> for details.</p>"},{"location":"#stay-connected","title":"Stay Connected","text":"<ul> <li>Discussions and RFC debates happen in GitHub Discussions (coming soon).</li> <li>Follow tagged releases as the manifesto and documentation evolve (v1.x, v2.x, etc.).</li> </ul>"},{"location":"ai-agents/","title":"AI Agents","text":"<p>AI agents in solid.ai operate as accountable members of the organization. They collaborate with humans, adhere to governance policies, and continuously improve through feedback.</p>"},{"location":"ai-agents/#agent-lifecycle","title":"Agent Lifecycle","text":"<ol> <li>Purpose Definition \u2013 Document mission, constraints, and success metrics.</li> <li>Design &amp; Training \u2013 Configure prompts, skill plugins, and safety filters.</li> <li>Deployment \u2013 Register the agent in the Cognitive Layer registry with metadata.</li> <li>Observation \u2013 Monitor performance, drift, and incident reports.</li> <li>Iteration \u2013 Adjust capabilities, retrain models, or retire agents via ADRs.</li> </ol>"},{"location":"ai-agents/#agent-roles","title":"Agent Roles","text":"<ul> <li>Insight Curator: Synthesizes data into narratives and dashboards.</li> <li>Automation Orchestrator: Coordinates multi-step workflows across systems.</li> <li>Compliance Sentinel: Flags policy deviations and anomalies.</li> <li>Learning Companion: Supports training, documentation, and knowledge management.</li> </ul>"},{"location":"ai-agents/#accountability-framework","title":"Accountability Framework","text":"<ul> <li>Assign human stewards responsible for oversight and ethical review.</li> <li>Maintain audit logs of agent decisions and interventions.</li> <li>Require explainability artifacts for critical actions (text summaries, trace IDs).</li> </ul>"},{"location":"ai-agents/#interaction-patterns","title":"Interaction Patterns","text":"<ul> <li>Co-Pilot Mode: Agent augments human decisions with recommendations.</li> <li>Auto-Resolve Mode: Agent executes predefined actions with alerting safeguards.</li> <li>Escalation Mode: Agent triggers human review when confidence drops below thresholds.</li> </ul>"},{"location":"ai-agents/#tooling-guidelines","title":"Tooling Guidelines","text":"<ul> <li>Prefer modular architectures supporting multiple model providers.</li> <li>Use lightweight adapters to integrate with messaging, issue trackers, and workflow tools.</li> <li>Align testing strategies with failure modes (simulation, sandbox, A/B environments).</li> </ul>"},{"location":"architecture/","title":"Architecture","text":"<p>The solid.ai architecture connects six interdependent layers. Each layer is modular yet synchronized through shared contracts, data flows, and governance policies.</p>"},{"location":"architecture/#layer-overview","title":"Layer Overview","text":"<ol> <li>Purpose Layer \u2013 Sets strategic intent, missions, and ethical guardrails.</li> <li>Data Spine \u2013 Provides unified access to data products, observability, and lineage.</li> <li>Cognitive Layer \u2013 Hosts AI agents, orchestration engines, and learning loops.</li> <li>Automation Mesh \u2013 Executes cross-domain workflows through event-driven automation.</li> <li>Organizational Layer \u2013 Defines human and AI team topology, roles, and rituals.</li> <li>Governance &amp; Ethics Layer \u2013 Ensures compliance, accountability, and trust.</li> </ol>"},{"location":"architecture/#integration-patterns","title":"Integration Patterns","text":"<ul> <li>Event Streams: Connect Cognitive outputs to Automation actions using shared event schemas.</li> <li>Contracts: APIs, data products, and prompts share versioned contracts stored in the Data Spine.</li> <li>Feedback Loops: Telemetry from the Automation Mesh and Organizational Layer feeds learning systems.</li> </ul>"},{"location":"architecture/#technology-agnostic","title":"Technology Agnostic","text":"<p>solid.ai is intentionally technology-neutral. It focuses on patterns that can be implemented with cloud-native, on-premises, or hybrid stacks. Reference implementations may use tools such as:</p> <ul> <li>Data: Lakehouse platforms, semantic layers, data catalogs.</li> <li>Cognitive: Orchestration frameworks (e.g., MAGI), LLM service layers, agent runtimes.</li> <li>Automation: Low-code orchestrators, BPMN engines, event-driven platforms, RPA.</li> <li>Observability: OpenTelemetry, model monitoring solutions, governance dashboards.</li> </ul>"},{"location":"architecture/#interoperability","title":"Interoperability","text":"<ul> <li>Use open standards wherever possible (JSON Schema, AsyncAPI, OpenAPI, SQL, GraphQL).</li> <li>Provide adapters for proprietary systems while preserving transparent interfaces.</li> <li>Expect multiple AI providers; design for model-agnostic orchestration.</li> </ul>"},{"location":"architecture/#resilience-and-fail-safes","title":"Resilience and Fail-Safes","text":"<ul> <li>Design layered fallback modes for critical processes.</li> <li>Establish human-in-the-loop checkpoints for high-risk decisions.</li> <li>Monitor saturation points (compute cost, data freshness, queue depth) and trigger alerts.</li> </ul>"},{"location":"architecture/#diagram","title":"Diagram","text":"<p>See <code>DIAGRAMS/solid-ai-architecture.mmd</code> for a Mermaid representation of the layer interactions.</p>"},{"location":"automation-sipoc/","title":"Automation SIPOC","text":"<p>The SIPOC (Suppliers, Inputs, Process, Outputs, Customers) model ensures automations stay aligned with purpose, data integrity, and ethical guardrails.</p>"},{"location":"automation-sipoc/#sipoc-template","title":"SIPOC Template","text":"Stage Description Guidance Suppliers Human teams, AI agents, data sources feeding the process Validate provenance, consent, and licensing Inputs Data artifacts, triggers, operating context Define contracts and observability metrics Process Steps orchestrated by the Automation Mesh Map decision points, human-in-the-loop checkpoints Outputs Deliverables, events, decisions, or actions Measure quality, latency, and ethical impact Customers Stakeholders, downstream systems, feedback loops Capture satisfaction and learning signals"},{"location":"automation-sipoc/#automation-guardrails","title":"Automation Guardrails","text":"<ul> <li>Map each automation to an explicit purpose statement linked to the Manifesto.</li> <li>Require Cognitive Layer validation before promotion to production.</li> <li>Instrument flows with telemetry covering success rate, drift, and exceptions.</li> <li>Provide rollback paths and manual override capabilities.</li> </ul>"},{"location":"automation-sipoc/#example-workflow","title":"Example Workflow","text":"<ol> <li>Supplier: Customer feedback platform, sentiment analysis agent.</li> <li>Input: Daily feedback summary, historical satisfaction thresholds.</li> <li>Process: Cognitive agent clusters insights, automation triggers prioritization tasks.</li> <li>Output: Ranked backlog with recommended squad assignments.</li> <li>Customer: Product leadership reviews and approves actions.</li> </ol>"},{"location":"automation-sipoc/#documentation","title":"Documentation","text":"<ul> <li>Store SIPOC artifacts in <code>/DOCS/automation/</code> (future expansion) or link from RFCs.</li> <li>Update diagrams in <code>DIAGRAMS/organizational-flow.mmd</code> to reflect evolving processes.</li> </ul>"},{"location":"glossary/","title":"Glossary","text":"Term Definition ADR (Architecture Decision Record) Lightweight document capturing a significant technical decision, context, and consequences. AI Agent Software entity with defined goals, autonomy, and accountability operating within the Cognitive Layer. Automation Mesh Network of orchestrated workflows connecting AI, data, and human actions. Cognitive Layer Layer responsible for intelligence\u2014agents, orchestration engines, and learning systems. Data Spine Unified data foundation that governs access, quality, and observability across the organization. Governance Circle Multi-disciplinary group overseeing ethics, compliance, and decision quality. MAGI Reference orchestration pattern for coordinating multiple models and agents (pluggable implementation). Manifesto Foundational narrative defining purpose, principles, and roadmap for solid.ai. Playbook Task-oriented guide describing how squads, pools, or operations implement the framework. RFC (Request for Comments) Proposal document for material changes to architecture, governance, or organizational design. SIPOC Supplier-Input-Process-Output-Customer model used to align automations with purpose and ethics. Squad Cross-functional, outcome-oriented team combining human expertise and AI agents."},{"location":"governance-ethics/","title":"Governance &amp; Ethics","text":"<p>Governance in solid.ai ensures intelligence scales responsibly. Ethics is woven into every layer through transparency, accountability, and continuous oversight.</p>"},{"location":"governance-ethics/#pillars","title":"Pillars","text":"<ol> <li>Cognitive Transparency \u2013 Document data, models, prompts, and decision logic.</li> <li>Human Curatorship \u2013 Maintain clear roles for human reviewers and escalation paths.</li> <li>System Observability \u2013 Instrument pipelines with metrics, traces, and alerts.</li> <li>Continuous Feedback \u2013 Capture post-decision reviews and user sentiment.</li> <li>Modular Independence \u2013 Allow components to evolve without cascading risk.</li> </ol>"},{"location":"governance-ethics/#oversight-structures","title":"Oversight Structures","text":"<ul> <li>Governance Circle: Multi-disciplinary board that evaluates RFCs touching ethics or compliance.</li> <li>Ethics Review: Lightweight checklist embedded in PR templates.</li> <li>Incident Response: Runbooks for AI or automation incidents, including notification protocols.</li> </ul>"},{"location":"governance-ethics/#policy-lifecycle","title":"Policy Lifecycle","text":"<ol> <li>Draft policy via RFC with clear scope and rationale.</li> <li>Pilot with one squad; capture telemetry and qualitative feedback.</li> <li>Iterate based on results, publish decision via ADR.</li> <li>Institutionalize with updated playbooks, training, and automation changes.</li> </ol>"},{"location":"governance-ethics/#compliance-considerations","title":"Compliance Considerations","text":"<ul> <li>Align with applicable regulations (GDPR, LGPD, HIPAA, etc.) based on deployment context.</li> <li>Track data residency, retention, and consent requirements in the Data Spine catalog.</li> <li>Maintain logs for audit trails with immutable storage and retention policies.</li> </ul>"},{"location":"governance-ethics/#ethical-risk-assessment","title":"Ethical Risk Assessment","text":"<ul> <li>Evaluate bias, drift, and harm potential before deployment.</li> <li>Rate impact severity and required mitigation steps.</li> <li>Reassess regularly or after material changes to models, data, or workflows.</li> </ul>"},{"location":"observability/","title":"Observability","text":"<p>Observability is the nervous system feedback loop of solid.ai. It links data, cognition, automation, and organizational response into measurable signals.</p>"},{"location":"observability/#objectives","title":"Objectives","text":"<ul> <li>Detect anomalies or degradations in AI behavior and automation performance.</li> <li>Provide timely insights for human overseers and governance circles.</li> <li>Enable continuous learning by capturing outcomes and feedback.</li> </ul>"},{"location":"observability/#telemetry-layers","title":"Telemetry Layers","text":"Layer Signals Tooling Examples Purpose OKRs, mission health, stakeholder sentiment Strategy dashboards, survey analytics Data Spine Data freshness, lineage, quality scores Data catalogs, Great Expectations Cognitive Model accuracy, confidence intervals, drift metrics ML observability platforms, custom dashboards Automation Mesh Throughput, latency, error rates, fallback events Event logs, APM, workflow monitors Organizational Capacity, cycle time, team health, knowledge flow People analytics, retrospectives Governance Incident counts, review SLAs, compliance checklists GRC tools, ticketing systems"},{"location":"observability/#design-principles","title":"Design Principles","text":"<ul> <li>Instrument every critical path with traceable IDs.</li> <li>Favor open standards (OpenTelemetry) for metrics, logs, and traces.</li> <li>Surface insights in both human-readable and machine-actionable formats.</li> </ul>"},{"location":"observability/#feedback-mechanisms","title":"Feedback Mechanisms","text":"<ul> <li>Integrate observability data into retrospectives and governance reviews.</li> <li>Provide agents with telemetry streams to adapt behavior autonomously.</li> <li>Automate alerts with thresholds and anomaly detection, but require human acknowledgement for critical escalations.</li> </ul>"},{"location":"observability/#knowledge-capture","title":"Knowledge Capture","text":"<ul> <li>Store post-incident reviews in the RFC or ADR directories.</li> <li>Maintain a changelog documenting major enhancements or regressions.</li> <li>Publish quarterly observability reports summarizing trends and improvements.</li> </ul>"},{"location":"organizational-model/","title":"Organizational Model","text":"<p>solid.ai organizes humans and AI agents into adaptive structures optimized for co-creation, learning, and resilience.</p>"},{"location":"organizational-model/#structural-elements","title":"Structural Elements","text":"<ul> <li>Squads: Cross-functional units focused on delivering customer or stakeholder outcomes.</li> <li>Pools: Shared capability hubs (e.g., Data, AI Ops, Design) that provide expertise on demand.</li> <li>Cognitive Agents: AI teammates embedded in squads or pools with defined responsibilities.</li> <li>Governance Circles: Multi-disciplinary groups that review ethics, observability, and compliance.</li> </ul>"},{"location":"organizational-model/#operating-rhythm","title":"Operating Rhythm","text":"Cadence Activity Participants Weekly Outcome review &amp; adaptive planning Squad leads, embedded agents Biweekly Governance sync Governance circles, compliance officers Monthly Portfolio alignment Executive sponsors, pool leads Quarterly Strategy iteration &amp; manifesto review Leadership council"},{"location":"organizational-model/#decision-flows","title":"Decision Flows","text":"<ol> <li>Squads identify opportunities and produce RFC drafts.</li> <li>Pools validate feasibility, data readiness, and AI agent design.</li> <li>Governance circles assess ethical impact and observability requirements.</li> <li>Approved RFCs trigger updates to playbooks, automation flows, and documentation.</li> </ol>"},{"location":"organizational-model/#roles-responsibilities","title":"Roles &amp; Responsibilities","text":"<ul> <li>Human Lead: Maintains purpose alignment and stakeholder engagement.</li> <li>AI Orchestrator: Automates data gathering, summarization, and decision support.</li> <li>Ops Steward: Ensures compliance, telemetry, and incident response readiness.</li> <li>Learning Curator: Synthesizes feedback, publishes retrospectives, updates knowledge bases.</li> </ul>"},{"location":"organizational-model/#talent-development","title":"Talent Development","text":"<ul> <li>Promote rotational programs between squads and pools to diffuse expertise.</li> <li>Provide AI literacy training and ethical decision-making workshops.</li> <li>Encourage shared ownership of AI-assisted deliverables.</li> </ul>"},{"location":"organizational-model/#change-management","title":"Change Management","text":"<ul> <li>Major structural shifts require RFC approval.</li> <li>ADRs document tooling and platform choices that impact organizational behavior.</li> <li>Retired structures should leave a knowledge trail in playbooks and docs.</li> </ul>"},{"location":"overview/","title":"Overview","text":"<p>solid.ai is the organizational nervous system for AI-native companies. It provides a holistic blueprint for connecting purpose, data, intelligence, automation, and organizational design into an ethical, adaptive ecosystem.</p>"},{"location":"overview/#objectives","title":"Objectives","text":"<ul> <li>Establish a shared language for human\u2013AI collaboration.</li> <li>Offer reference models that teams can tailor to their own context.</li> <li>Provide governance guardrails that scale with experimentation.</li> <li>Enable continuous learning loops across strategy, delivery, and operations.</li> </ul>"},{"location":"overview/#key-artifacts","title":"Key Artifacts","text":"<ul> <li>Manifesto: Anchors philosophy and roadmap.</li> <li>Principles: Codify ethical, human-centered decision making.</li> <li>Architecture: Shows how data, cognition, and automation interlock.</li> <li>Playbooks: Actionable guidance for squads, pools, and operations.</li> <li>RFCs &amp; ADRs: Capture decisions that evolve the framework over time.</li> </ul>"},{"location":"overview/#how-to-navigate-the-repository","title":"How to Navigate the Repository","text":"<ol> <li>Start with the Manifesto for context and intent.</li> <li>Read the numbered documents in <code>DOCS/</code> for a deep dive into each layer.</li> <li>Explore Mermaid diagrams in <code>DIAGRAMS/</code> to visualize interactions.</li> <li>Review RFCs and ADRs to understand how the framework evolves.</li> <li>Apply the playbooks to bring concepts into operational practice.</li> </ol>"},{"location":"overview/#versioning","title":"Versioning","text":"<ul> <li><code>main</code> holds stable releases of the framework.</li> <li><code>dev</code> is the integration branch for approved RFCs.</li> <li>Manifesto updates follow semantic versioning (v1.0.0, v1.1.0, etc.).</li> </ul>"},{"location":"principles/","title":"Principles","text":"<p>solid.ai principles encode the behaviors required to build responsible, adaptive, AI-native organizations. They apply across strategy, design, and operations.</p>"},{"location":"principles/#purpose-led-decisions","title":"Purpose-Led Decisions","text":"<ul> <li>Anchor every automation or AI implementation in a human-centered purpose.</li> <li>Resist optimizing for efficiency at the expense of values or trust.</li> </ul>"},{"location":"principles/#living-architecture","title":"Living Architecture","text":"<ul> <li>Treat the organization as a living organism that learns and evolves.</li> <li>Prefer modular designs that can adapt without systemic collapse.</li> </ul>"},{"location":"principles/#continuous-learning","title":"Continuous Learning","text":"<ul> <li>Capture feedback from every interaction\u2014human or machine.</li> <li>Use data, retrospectives, and telemetry to drive iterative improvements.</li> </ul>"},{"location":"principles/#intelligent-decentralization","title":"Intelligent Decentralization","text":"<ul> <li>Empower teams at the edge with decision-making authority and transparent data.</li> <li>Maintain coherence through shared principles, playbooks, and guardrails.</li> </ul>"},{"location":"principles/#cognitive-workforce","title":"Cognitive Workforce","text":"<ul> <li>Define explicit roles, responsibilities, and metrics for AI agents.</li> <li>Ensure accountability and traceability for automated decisions.</li> </ul>"},{"location":"principles/#ethical-automation","title":"Ethical Automation","text":"<ul> <li>Make automations explainable, auditable, and observable by design.</li> <li>Balance automation throughput with human oversight and consent.</li> </ul>"},{"location":"principles/#scalable-simplicity","title":"Scalable Simplicity","text":"<ul> <li>Strive for solutions that are simple to understand, extend, and govern.</li> <li>Let complexity emerge from interaction, not upfront design.</li> </ul>"},{"location":"principles/#humanmachine-symbiosis","title":"Human\u2013Machine Symbiosis","text":"<ul> <li>Combine human empathy, creativity, and purpose with AI scale and precision.</li> <li>Foster collaboration rituals where humans and AI agents co-create value.</li> </ul>"}]}