# Product Manager Quick Reference Card

**Role:** Product Manager | **Framework:** SOLID.AI | **Version:** 1.0

---

## Core AI Prompting Patterns for Product Managers

### 1. Purpose-First Feature Definition

```
I'm considering a new feature: [FEATURE IDEA].

Before we prioritize or build, help me articulate:

1. **Human Need:** What real problem does this solve?
2. **Purpose Alignment:** How does this serve our mission and values?
3. **Success Beyond Metrics:** What does "good" look like qualitatively?
4. **Ethical Considerations:** Who might be harmed? What could go wrong?
5. **AI Opportunity:** Could AI augment or automate parts of this?

Provide a structured feature brief.
```

**Use when:** Evaluating new feature ideas

---

### 2. User Story with AI Context

```
Write user stories for [FEATURE] considering human-AI collaboration:

As a [USER TYPE]
I want to [ACTION]
So that [OUTCOME]

Include:
- Stories for human-only interaction
- Stories for AI-augmented workflows
- Stories for AI-autonomous actions with human oversight
- Edge cases where AI should defer to humans

Format using standard acceptance criteria.
```

**Use when:** Defining requirements for AI-enabled features

---

### 3. Roadmap Prioritization

```
Help me prioritize these initiatives using SOLID.AI principles:

[LIST INITIATIVES]

Evaluate each on:
1. Purpose alignment (mission/values fit)
2. User value (impact on real needs)
3. Learning potential (data/insights gained)
4. Ethical risk (potential harms)
5. AI readiness (data/capability maturity)
6. Organizational capacity (squad/pool availability)

Provide a prioritized recommendation with rationale.
```

**Use when:** Planning quarterly or annual roadmaps

---

### 4. Hypothesis-Driven Experimentation

```
I want to test the hypothesis: [HYPOTHESIS].

Design an experiment using the SOLID.AI learning loop:

1. **Hypothesis:** Clear, testable statement
2. **Metrics:** Leading and lagging indicators
3. **AI Role:** How AI supports or executes the experiment
4. **Human Oversight:** What humans monitor and when
5. **Ethics Check:** Consent, privacy, bias considerations
6. **Learning Capture:** How we document and share findings

Format as an experiment brief.
```

**Use when:** Validating assumptions or new approaches

---

### 5. Stakeholder Communication

```
Translate this technical decision into stakeholder-friendly language:

[TECHNICAL DETAIL]

Craft a message that:
- Connects to business outcomes and user value
- Explains AI's role in accessible terms
- Addresses risks and mitigation
- Highlights ethical safeguards
- Proposes clear next steps or decisions needed

Target audience: [SPECIFY: executives, customers, board, etc.]
```

**Use when:** Communicating complex AI/technical topics

---

### 6. Metrics Definition

```
Define success metrics for [INITIATIVE/FEATURE]:

Include:
1. **Purpose Metrics:** How we measure mission alignment
2. **User Metrics:** Adoption, satisfaction, outcomes
3. **AI Performance:** Accuracy, latency, cost
4. **Ethics Metrics:** Fairness, transparency, consent
5. **Learning Metrics:** Insights gained, iteration velocity
6. **Organizational Health:** Team engagement, cognitive load

Identify leading vs. lagging indicators.
```

**Use when:** Setting goals and measurement frameworks

---

### 7. Competitive Analysis with AI Lens

```
Analyze [COMPETITOR/PRODUCT] through the SOLID.AI lens:

Compare:
1. How they use AI (co-pilot, automation, intelligence)
2. User experience and human-AI balance
3. Transparency and ethical practices
4. Data utilization and privacy approach
5. Organizational model (if known)

What can we learn? What should we avoid?
```

**Use when:** Understanding the competitive landscape

---

### 8. Squad Charter Creation

```
Draft a squad charter for [MISSION/GOAL]:

Include:
- **Purpose:** Why this squad exists (aligned to company mission)
- **Scope:** What's in/out of their domain
- **Outcomes:** What success looks like
- **AI Agents:** Which agents support this squad
- **Rituals:** Meetings, reviews, learning sessions
- **Metrics:** How we measure squad health and impact
- **Guardrails:** Constraints and escalation paths

Format using the SOLID.AI squad template.
```

**Use when:** Forming new teams or refocusing existing ones

---

### 9. Customer Feedback Analysis

```
Analyze this customer feedback using SOLID.AI principles:

[PASTE FEEDBACK: reviews, interviews, support tickets, etc.]

Identify:
1. Core user needs and pain points
2. Purpose-mission alignment gaps
3. AI opportunity areas (augment or automate)
4. Ethical concerns or trust issues
5. Data gaps preventing better solutions
6. Patterns across feedback sources

Summarize with actionable insights.
```

**Use when:** Processing user research or feedback

---

### 10. Release Planning with Observability

```
Plan the release of [FEATURE] with built-in learning:

1. **Rollout Strategy:** Phased, canary, or full?
2. **Observability:** What telemetry do we need?
3. **Success Criteria:** When do we expand vs. rollback?
4. **AI Behavior:** How do we monitor AI agent actions?
5. **Human Oversight:** Who watches what, when?
6. **Feedback Loops:** How do we gather and act on learnings?
7. **Communication Plan:** User messaging and support prep

Generate a release checklist.
```

**Use when:** Planning feature launches

---

## SOLID.AI Product Manager Mindset

✅ **Do:**
- Lead with purpose, not just features
- Design for human-AI symbiosis, not replacement
- Build ethics and transparency into every decision
- Create tight feedback loops for continuous learning
- Empower squads with clear purpose and autonomy
- Measure what matters, not just what's easy

❌ **Avoid:**
- "AI-washing" (adding AI without clear value)
- Optimizing metrics at the expense of user trust
- Black-box AI without explainability
- Shipping without observability or learning plans
- Ignoring ethical implications until crisis
- Top-down roadmaps that bypass squad expertise

---

## Collaboration Patterns

### With Developers
- Share the "why" before the "what"
- Co-create acceptance criteria
- Review AI agent definitions together
- Participate in demos and retrospectives

### With AI/Data Teams
- Define success metrics jointly
- Understand AI capabilities and limitations
- Design ethical guardrails collaboratively
- Review model performance regularly

### With Stakeholders
- Translate technical into business language
- Connect initiatives to strategic purpose
- Communicate risks and mitigation clearly
- Share learning and iteration plans

---

## Key Resources

- **Organizational Model:** [DOCS/03-organizational-model.md](../../DOCS/03-organizational-model.md)
- **Squad Playbook:** [PLAYBOOKS/playbook-squads.md](../../PLAYBOOKS/playbook-squads.md)
- **Governance & Ethics:** [DOCS/06-governance-ethics.md](../../DOCS/06-governance-ethics.md)
- **Manifesto:** [MANIFESTO/solid-ai-manifesto-v1.md](../../MANIFESTO/solid-ai-manifesto-v1.md)
- **Glossary:** [DOCS/glossary.md](../../DOCS/glossary.md)

---

**Version:** 1.0 | **Last Updated:** November 2025 | **Feedback:** [GitHub Issues](https://github.com/gusafr/midora-solid-ai/issues)
